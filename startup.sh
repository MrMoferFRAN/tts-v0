#!/bin/bash
# ğŸš€ RUNPOD CSM VOICE CLONING STARTUP - VERSIÃ“N ROBUSTA
# Configurado para: runpod/pytorch:2.1.1-py3.10-cuda12.1.1-devel-ubuntu22.04
# Sistema: CSM-1B nativo de Transformers 4.52.4+
# Incluye: Dependencias de audio (libsndfile, ffmpeg, soundfile, librosa) para backends robustos

set -e  # Exit on any error

echo "ğŸ¯ RUNPOD CSM VOICE CLONING - STARTUP ROBUSTO"
echo "============================================================"

# 1. Environment Verification
echo "ğŸ” 1. Verificando entorno del sistema..."
cd /workspace/tts-v0

# Check GPU
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1
echo "âœ… GPU verification complete"

# 2. Setup environment variables
echo "ğŸ”‘ 2. Configurando variables de entorno..."
# Manejar RunPod Secrets y variables de entorno
if [ -n "$RUNPOD_SECRET_HF_TOKEN" ]; then
    export HF_TOKEN="$RUNPOD_SECRET_HF_TOKEN"
    echo "âœ… HF_TOKEN configurado desde RunPod Secret"
elif [ -n "$HF_TOKEN" ]; then
    echo "âœ… HF_TOKEN configurado desde variable de entorno"
else
    echo "âŒ ERROR: HF_TOKEN no configurado"
    echo "ğŸ’¡ Configurar en RunPod usando Secrets: RUNPOD_SECRET_HF_TOKEN"
    echo "ğŸ’¡ O como variable de entorno: HF_TOKEN"
    exit 1
fi

# Configurar autenticaciÃ³n de Hugging Face
echo "ğŸ” Configurando autenticaciÃ³n de Hugging Face..."
mkdir -p ~/.cache/huggingface
echo "$HF_TOKEN" > ~/.cache/huggingface/token

# Configurar git credentials para Hugging Face
git config --global credential.helper store
echo "https://MrMoferFRAN:$HF_TOKEN@huggingface.co" > ~/.git-credentials

# TambiÃ©n configurar usando huggingface-hub
pip install --no-cache-dir huggingface-hub --upgrade
python -c "from huggingface_hub import login; login('$HF_TOKEN')" 2>/dev/null || echo "âš ï¸ huggingface-hub login failed, using git credentials"

export NO_TORCH_COMPILE=1
export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"
echo 'export NO_TORCH_COMPILE=1' >> ~/.bashrc
echo 'export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"' >> ~/.bashrc
echo "âœ… Variables de entorno y autenticaciÃ³n configuradas"

# 3. INSTALAR DEPENDENCIAS CRÃTICAS PRIMERO
echo "ğŸ”§ 3. INSTALANDO DEPENDENCIAS CRÃTICAS..."
pip install --no-cache-dir \
    "transformers>=4.52.1" \
    "accelerate>=0.20.0" \
    fastapi \
    uvicorn \
    python-multipart \
    aiofiles \
    --upgrade

echo "âœ… Dependencias crÃ­ticas instaladas"

# 3.5. INSTALAR DEPENDENCIAS DE AUDIO (CRÃTICO)
echo "ğŸ”Š 3.5. INSTALANDO DEPENDENCIAS DE AUDIO..."
echo "ğŸ“¦ Instalando librerÃ­as de sistema para audio..."

# Instalar librerÃ­as de sistema necesarias para torchaudio backends
apt-get update && apt-get install -y \
    libsndfile1 \
    libsndfile1-dev \
    ffmpeg \
    --no-install-recommends

echo "ğŸ“¦ Instalando soundfile y librosa para manejo robusto de archivos de audio..."
pip install --no-cache-dir soundfile librosa

# Verificar que los backends de audio estÃ©n disponibles
echo "ğŸ” Verificando backends de audio..."
python -c "
import torchaudio
backends = torchaudio.list_audio_backends()
print(f'âœ… TorchAudio backends disponibles: {backends}')

try:
    import soundfile as sf
    print('âœ… SoundFile disponible')
except ImportError:
    print('âŒ SoundFile no disponible')
    exit(1)

try:
    import librosa
    print('âœ… Librosa disponible')
except ImportError:
    print('âŒ Librosa no disponible')
    exit(1)

if not backends:
    print('âŒ No hay backends de audio disponibles para torchaudio')
    print('âš ï¸  Esto podrÃ­a causar errores al guardar archivos de audio')
    exit(1)
else:
    print('âœ… Backends de audio configurados correctamente')
"

if [ $? -ne 0 ]; then
    echo "âŒ Error configurando dependencias de audio"
    exit 1
fi

echo "âœ… Dependencias de audio instaladas y verificadas"

# 4. Verificar / descargar modelo CSM-1B (MÃ‰TODO ROBUSTO CON HUGGINGFACE_HUB)
echo "ğŸ” 4. Verificando modelo CSM-1B..."
MODEL_DIR="./models/sesame-csm-1b"

# Verificar si ya existe el modelo completo
if [ -f "$MODEL_DIR/config.json" ] && ls "$MODEL_DIR"/transformers-*-of-*.safetensors 1>/dev/null 2>&1; then
    model_size=$(du -sh "$MODEL_DIR" | cut -f1)
    echo "âœ… Modelo CSM-1B encontrado: $model_size"
    echo "ğŸ“‹ Archivos safetensors encontrados:"
    ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors
else
    echo "ğŸ”„ Descargando modelo CSM-1B con huggingface_hub (mÃ©todo robusto)..."
    
    # Asegurar que huggingface_hub estÃ© actualizado
    pip install --no-cache-dir huggingface_hub --upgrade
    
    # Crear directorio models si no existe
    mkdir -p models
    
    # Descargar usando huggingface_hub (mÃ¡s robusto que git-lfs)
    python - <<'PY'
import os
from huggingface_hub import snapshot_download

print("ğŸ“¥ Iniciando descarga del modelo CSM-1B...")
print("ğŸ”— Repo: sesame/csm-1b")
print("ğŸ“ Destino: models/sesame-csm-1b")

try:
    snapshot_download(
        repo_id="sesame/csm-1b",
        local_dir="models/sesame-csm-1b",
        local_dir_use_symlinks=False,  # copia real, sin symlinks â†’ evita problemas en contenedores
        token=os.environ.get("HF_TOKEN"),
        resume_download=True  # continÃºa descarga si se interrumpiÃ³
    )
    print("âœ… Descarga completada exitosamente")
except Exception as e:
    print(f"âŒ Error durante la descarga: {e}")
    exit(1)
PY

    if [ $? -ne 0 ]; then
        echo "âŒ Error descargando modelo con huggingface_hub"
        exit 1
    fi
fi

# VerificaciÃ³n exhaustiva de archivos crÃ­ticos
echo "ğŸ” Verificando integridad del modelo..."

# Verificar archivos safetensors especÃ­ficos
if ! ls "$MODEL_DIR"/transformers-*-of-*.safetensors 1>/dev/null 2>&1; then
    echo "âŒ No se han descargado los archivos safetensors"
    echo "ğŸ“‹ Archivos esperados:"
    echo "   - transformers-00001-of-00002.safetensors"
    echo "   - transformers-00002-of-00002.safetensors"
    echo "ğŸ“ Contenido actual del directorio:"
    ls -la "$MODEL_DIR"/ || echo "Directorio no existe"
    exit 1
fi

# Verificar archivos especÃ­ficos mencionados en el error
required_files=(
    "$MODEL_DIR/transformers-00001-of-00002.safetensors"
    "$MODEL_DIR/transformers-00002-of-00002.safetensors"
    "$MODEL_DIR/config.json"
    "$MODEL_DIR/tokenizer.json"
)

missing_files=()
for file in "${required_files[@]}"; do
    if [ ! -f "$file" ]; then
        missing_files+=("$file")
    fi
done

if [ ${#missing_files[@]} -gt 0 ]; then
    echo "âŒ Archivos faltantes:"
    for file in "${missing_files[@]}"; do
        echo "   - $file"
    done
    exit 1
fi

echo "âœ… Todos los archivos crÃ­ticos del modelo estÃ¡n presentes:"
echo "ğŸ“‹ Archivos safetensors verificados:"
ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors

# Mostrar tamaÃ±o total del modelo
model_size=$(du -sh "$MODEL_DIR" | cut -f1)
echo "ğŸ“¦ TamaÃ±o total del modelo: $model_size"

# 4.1 DESCARGAR VARIANTE TURBO INT8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ” 4.1 Verificando modelo TURBO INT8..."
TURBO_DIR="./models/csm-1b-turbo"

# Si el safetensor INT8 no existe, lo descargamos
if [ ! -f "$TURBO_DIR/model_int8.safetensors" ]; then
    echo "ğŸ”„ Descargando INT8 turbo (lunahr/csm-1b-safetensors-quants)â€¦"
    
    pip install --no-cache-dir huggingface_hub --upgrade
    
    python - <<'PY'
import os, sys
from huggingface_hub import snapshot_download

try:
    snapshot_download(
        repo_id="lunahr/csm-1b-safetensors-quants",
        local_dir="models/csm-1b-turbo",
        local_dir_use_symlinks=False,
        allow_patterns=[
            "model_int8.safetensors",        # pesos INT8 (â‰ˆ1.55 GB)
            "config.json",
            "tokenizer.json", 
            "generation_config.json",
            "special_tokens_map.json",
            "*.txt"
        ],
        resume_download=True,
        token=os.environ.get("HF_TOKEN"),
    )
    print("âœ… INT8 turbo descargado con Ã©xito")
except Exception as e:
    print(f"âŒ Error descargando INT8 turbo: {e}")
    sys.exit(1)
PY

    if [ $? -ne 0 ]; then
        echo "âŒ Error descargando modelo INT8 turbo"
        exit 1
    fi
else
    echo "âœ… INT8 turbo ya presente"
fi

# VerificaciÃ³n rÃ¡pida
if [ -f "$TURBO_DIR/model_int8.safetensors" ] && [ -f "$TURBO_DIR/config.json" ]; then
    size_int8=$(du -sh "$TURBO_DIR/model_int8.safetensors" | cut -f1)
    echo "ğŸ“¦ INT8 turbo listo (${size_int8}) â†’ $TURBO_DIR"
else
    echo "âŒ Faltan archivos crÃ­ticos del INT8 turbo"
    echo "ğŸ“‹ Archivos esperados:"
    echo "   - $TURBO_DIR/model_int8.safetensors"
    echo "   - $TURBO_DIR/config.json"
    echo "ğŸ“ Contenido actual:"
    ls -la "$TURBO_DIR/" 2>/dev/null || echo "Directorio no existe"
    exit 1
fi

# ---------------------------------------------------------------------------
# 4.2 COMPLETAR METADATOS DEL TURBO INT8
# ---------------------------------------------------------------------------
echo "ğŸ” 4.2 Completando metadatos del turbo INT8â€¦"
TURBO_DIR="./models/csm-1b-turbo"
BASE_DIR="./models/sesame-csm-1b"  # ya lo tienes completo

# 1) Si el repositorio INT8 contiene los ficheros, descÃ¡rgalos
python - <<'PY'
import os, sys
from huggingface_hub import snapshot_download

need = {
    "tokenizer.json",
    "tokenizer_config.json", 
    "special_tokens_map.json",
    "processor_config.json",
    "preprocessor_config.json",
    "chat_template.json",
    "generation_config.json",
}

have = set(os.listdir("models/csm-1b-turbo"))
missing = need - have

if missing:
    print(f"ğŸ”„ Faltan {len(missing)} archivos en turbo â†’ intentando descargarlosâ€¦")
    try:
        snapshot_download(
            repo_id="lunahr/csm-1b-safetensors-quants",
            local_dir="models/csm-1b-turbo",
            allow_patterns=list(missing),
            local_dir_use_symlinks=False,
            resume_download=True,
            token=os.environ.get("HF_TOKEN"),
        )
        print("âœ… Metadatos adicionales descargados")
    except Exception as e:
        print(f"âš ï¸ No se pudieron descargar algunos metadatos: {e}")
        print("ğŸ’¡ Se intentarÃ¡ copiar desde el modelo base")
else:
    print("âœ… Todos los metadatos ya estÃ¡n presentes")
PY

# 2) Si aÃºn faltan, cÃ³pialos del modelo "normal"
for f in tokenizer.json tokenizer_config.json special_tokens_map.json \
         processor_config.json preprocessor_config.json chat_template.json \
         generation_config.json; do
    if [ ! -f "$TURBO_DIR/$f" ] && [ -f "$BASE_DIR/$f" ]; then
        echo "ğŸ“¥ Copiando $f desde modelo base"
        cp "$BASE_DIR/$f" "$TURBO_DIR/"
    fi
done

# 3) VerificaciÃ³n final
missing_critical=()
for f in tokenizer.json processor_config.json config.json; do
    if [ ! -f "$TURBO_DIR/$f" ]; then
        missing_critical+=("$f")
    fi
done

if [ ${#missing_critical[@]} -gt 0 ]; then
    echo "âŒ Faltan archivos crÃ­ticos para AutoProcessor:"
    for f in "${missing_critical[@]}"; do
        echo "   - $f"
    done
    echo "ğŸ“ Contenido actual de $TURBO_DIR:"
    ls -la "$TURBO_DIR/"
    exit 1
fi

echo "âœ… Metadatos del turbo completos"
echo "ğŸ“‹ Archivos de configuraciÃ³n verificados:"
ls -la "$TURBO_DIR"/*.json | sed 's/^/   /'

# 5. Verificar dataset Elise (opcional)
echo "ğŸ” 5. Verificando dataset Elise..."
if [ -d "./datasets/csm-1b-elise" ]; then
    echo "âœ… Dataset Elise CSM ya existe"
else
    echo "âš ï¸ Dataset Elise no encontrado (opcional)"
fi

# 6. VERIFICAR DEPENDENCIAS PYTHON
echo "ğŸ”§ 6. VERIFICANDO DEPENDENCIAS PYTHON..."

# Verificar Python packages crÃ­ticos
echo "ğŸ“¦ Verificando dependencias crÃ­ticas..."
python -c "
import sys
missing = []

try:
    import torch
    print(f'âœ… PyTorch: {torch.__version__}')
except ImportError:
    missing.append('torch>=2.0.0')

try:
    import transformers
    print(f'âœ… Transformers: {transformers.__version__}')
    # Verificar que sea una versiÃ³n que soporte CSM
    if hasattr(transformers, 'CsmForConditionalGeneration'):
        print('âœ… CSM support available')
    else:
        print('âŒ CSM support not available, need Transformers >= 4.52.1')
        missing.append('transformers>=4.52.1')
except ImportError:
    missing.append('transformers>=4.52.1')

try:
    import fastapi
    print(f'âœ… FastAPI: {fastapi.__version__}')
except ImportError:
    missing.append('fastapi')

try:
    import uvicorn
    print(f'âœ… Uvicorn available')
except ImportError:
    missing.append('uvicorn')

try:
    import torchaudio
    print(f'âœ… TorchAudio: {torchaudio.__version__}')
    
    # Verificar backends de audio
    backends = torchaudio.list_audio_backends()
    print(f'âœ… TorchAudio backends: {backends}')
    if not backends:
        print('âš ï¸  Sin backends de audio - puede causar problemas')
except ImportError:
    missing.append('torchaudio')

try:
    import soundfile as sf
    print(f'âœ… SoundFile: disponible')
except ImportError:
    missing.append('soundfile')

try:
    import librosa
    print(f'âœ… Librosa: disponible')
except ImportError:
    missing.append('librosa')

if missing:
    print(f'âŒ Missing packages: {missing}')
    sys.exit(1)
else:
    print('âœ… All critical dependencies available')
"

if [ $? -ne 0 ]; then
    echo "ğŸ”§ Instalando dependencias faltantes..."
    
    # Instalar Transformers actualizado
    pip install transformers>=4.52.1 --upgrade
    
    # Instalar dependencias de API y audio
    pip install fastapi uvicorn python-multipart aiofiles soundfile librosa
    
    # Verificar instalaciÃ³n
    python -c "
from transformers import CsmForConditionalGeneration, AutoProcessor
print('âœ… CSM imports working correctly')
"
fi

# 7. Configurar estructura de directorios
echo "ğŸ“ 7. Configurando estructura de directorios..."
mkdir -p outputs temp logs voices
echo "âœ… Directorios creados"

# 8. Verificar archivo de voz de referencia
echo "ğŸ” 8. Verificando archivos de voz de referencia..."
reference_voice_old="voices/fran-fem/Ah, Â¿en serio? Vaya, eso debe ser un poco incÃ³modo para tu equipo. Y Â¿cÃ³mo lo tomaron?.wav"
reference_voice_new="voices/fran-fem/fran_fem_sample.wav"

if [ -f "$reference_voice_new" ]; then
    echo "âœ… Archivo de referencia encontrado: $reference_voice_new"
elif [ -f "$reference_voice_old" ]; then
    echo "âš ï¸ Archivo con nombre problemÃ¡tico encontrado, renombrando..."
    cd voices/fran-fem && mv *.wav fran_fem_sample.wav && cd ../..
    echo "âœ… Archivo renombrado a: $reference_voice_new"
    
    # Actualizar profiles.json si existe
    if [ -f "voices/fran-fem/profiles.json" ]; then
        echo "ğŸ”§ Actualizando profiles.json..."
        python -c "
import json
from datetime import datetime

try:
    with open('voices/fran-fem/profiles.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Actualizar path del audio
    if 'profiles' in data and len(data['profiles']) > 0:
        data['profiles'][0]['name'] = 'fran_fem_sample'
        data['profiles'][0]['audio_path'] = '/workspace/tts-v0/voices/fran-fem/fran_fem_sample.wav'
        data['updated_at'] = datetime.now().isoformat()
        
        with open('voices/fran-fem/profiles.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print('âœ… profiles.json actualizado')
    else:
        print('âš ï¸ profiles.json no tiene el formato esperado')
except Exception as e:
    print(f'âŒ Error actualizando profiles.json: {e}')
"
    fi
else
    echo "âš ï¸ Archivo de referencia no encontrado"
    echo "ğŸ’¡ El sistema funcionarÃ¡, pero sin perfil de voz predefinido"
fi

# 9. Test robusto del sistema CSM
echo "ğŸ”§ 9. Probando sistema CSM..."
python -c "
import torch
from transformers import CsmForConditionalGeneration, AutoProcessor
import os

print('ğŸ” Testing CSM system...')

# Test modelo principal
try:
    model_path = './models/sesame-csm-1b'
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Verificar que los archivos especÃ­ficos existen
    safetensor_files = [
        'transformers-00001-of-00002.safetensors',
        'transformers-00002-of-00002.safetensors'
    ]
    
    print('ğŸ” Verificando archivos safetensors del modelo principal...')
    for file in safetensor_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024*1024)
            print(f'âœ… {file}: {size_mb:.1f} MB')
        else:
            print(f'âŒ {file}: NO ENCONTRADO')
            raise FileNotFoundError(f'Archivo crÃ­tico faltante: {file}')
    
    print(f'ğŸ“¥ Loading processor from {model_path}...')
    processor = AutoProcessor.from_pretrained(model_path)
    
    print(f'ğŸ“¥ Loading model on {device}...')
    model = CsmForConditionalGeneration.from_pretrained(
        model_path,
        device_map=device,
        torch_dtype=torch.float16 if device == 'cuda' else torch.float32
    )
    
    print('âœ… Modelo principal CSM test successful!')
    del model  # Liberar memoria para el test del turbo
    
except Exception as e:
    print(f'âŒ CSM main model test failed: {e}')
    import traceback
    traceback.print_exc()
    exit(1)

# Test modelo turbo INT8 si existe
turbo_path = './models/csm-1b-turbo'
if os.path.exists(os.path.join(turbo_path, 'model_int8.safetensors')):
    print('ğŸ” Testing modelo turbo INT8...')
    try:
        print(f'ğŸ“¥ Loading turbo processor from {turbo_path}...')
        turbo_processor = AutoProcessor.from_pretrained(turbo_path)
        
        print(f'ğŸ“¥ Loading turbo model (INT8) on {device}...')
        turbo_model = CsmForConditionalGeneration.from_pretrained(
            turbo_path,
            device_map=device,
            torch_dtype=torch.float16 if device == 'cuda' else torch.float32
        )
        
        print('âœ… Modelo turbo INT8 test successful!')
        del turbo_model  # Liberar memoria
        
    except Exception as e:
        print(f'âš ï¸ Turbo INT8 model test failed (optional): {e}')
        print('ğŸ’¡ El modelo principal sigue funcionando')
else:
    print('â„¹ï¸ Modelo turbo INT8 no disponible (opcional)')

# GPU info
if torch.cuda.is_available():
    gpu_info = torch.cuda.get_device_properties(0)
    memory_gb = gpu_info.total_memory / 1024**3
    print(f'ğŸ–¥ï¸ GPU: {gpu_info.name} ({memory_gb:.1f} GB)')

# Test torch.compiler compatibility
if not hasattr(torch.compiler, 'is_compiling'):
    print('âš ï¸  torch.compiler compatibility patch needed')
else:
    print('âœ… torch.compiler compatible')

print('âœ… Sistema CSM completamente funcional!')
"

if [ $? -ne 0 ]; then
    echo "âŒ Sistema CSM no funcionÃ³ correctamente"
    echo "ğŸ” InformaciÃ³n de debugging:"
    echo "ğŸ“ Contenido del directorio del modelo:"
    ls -la "$MODEL_DIR/" || echo "Directorio no accesible"
    exit 1
fi

# 10. InformaciÃ³n del sistema configurado
echo "ğŸ“Š 10. InformaciÃ³n del sistema configurado..."
echo "============================================================"
echo "ğŸ¤ CSM VOICE CLONING SYSTEM - READY"
echo "============================================================"
echo "ğŸ“¦ Sistema: CSM-1B nativo de Transformers"
echo "ğŸ¤– Modelo Principal: models/sesame-csm-1b ($(du -sh models/sesame-csm-1b | cut -f1))"
if [ -f "./models/csm-1b-turbo/model_int8.safetensors" ]; then
    echo "âš¡ Modelo Turbo INT8: models/csm-1b-turbo ($(du -sh models/csm-1b-turbo/model_int8.safetensors | cut -f1))"
else
    echo "âš ï¸ Modelo Turbo INT8: No disponible"
fi
echo "ğŸ­ Voces: $(ls voices/ 2>/dev/null | wc -l) perfiles disponibles"
echo "ğŸ”§ API: FastAPI + Uvicorn (voice_api_complete.py)"
echo "ğŸš€ Puerto: 7860"
echo "âœ… Archivos safetensors verificados:"
echo "   ğŸ“ Modelo Principal:"
ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors | sed 's/^/      /'
if [ -f "./models/csm-1b-turbo/model_int8.safetensors" ]; then
    echo "   âš¡ Modelo Turbo INT8:"
    ls -la "./models/csm-1b-turbo/model_int8.safetensors" | sed 's/^/      /'
fi
echo "============================================================"

# 11. Iniciar API
echo "ğŸš€ 11. Iniciando CSM Voice Cloning API..."

# Ejecutar API completa
python voice_api_complete.py
