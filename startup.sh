#!/bin/bash
# ðŸš€ RUNPOD CSM VOICE CLONING STARTUP - VERSIÃ“N ROBUSTA
# Configurado para: runpod/pytorch:2.1.1-py3.10-cuda12.1.1-devel-ubuntu22.04
# Sistema: CSM-1B nativo de Transformers 4.52.4+
# Incluye: Dependencias de audio (libsndfile, ffmpeg, soundfile, librosa) para backends robustos

set -e  # Exit on any error

echo "ðŸŽ¯ RUNPOD CSM VOICE CLONING - STARTUP ROBUSTO"
echo "============================================================"

# 1. Environment Verification
echo "ðŸ” 1. Verificando entorno del sistema..."
cd /workspace/tts-v0

# Check GPU
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1
echo "âœ… GPU verification complete"

# 2. Setup environment variables
echo "ðŸ”‘ 2. Configurando variables de entorno..."
# Manejar RunPod Secrets y variables de entorno
if [ -n "$RUNPOD_SECRET_HF_TOKEN" ]; then
    export HF_TOKEN="$RUNPOD_SECRET_HF_TOKEN"
    echo "âœ… HF_TOKEN configurado desde RunPod Secret"
elif [ -n "$HF_TOKEN" ]; then
    echo "âœ… HF_TOKEN configurado desde variable de entorno"
else
    echo "âŒ ERROR: HF_TOKEN no configurado"
    echo "ðŸ’¡ Configurar en RunPod usando Secrets: RUNPOD_SECRET_HF_TOKEN"
    echo "ðŸ’¡ O como variable de entorno: HF_TOKEN"
    exit 1
fi

# Configurar autenticaciÃ³n de Hugging Face
echo "ðŸ” Configurando autenticaciÃ³n de Hugging Face..."
mkdir -p ~/.cache/huggingface
echo "$HF_TOKEN" > ~/.cache/huggingface/token

# Configurar git credentials para Hugging Face
git config --global credential.helper store
echo "https://MrMoferFRAN:$HF_TOKEN@huggingface.co" > ~/.git-credentials

# TambiÃ©n configurar usando huggingface-hub
pip install --no-cache-dir huggingface-hub --upgrade
python -c "from huggingface_hub import login; login('$HF_TOKEN')" 2>/dev/null || echo "âš ï¸ huggingface-hub login failed, using git credentials"

export NO_TORCH_COMPILE=1
export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"
echo 'export NO_TORCH_COMPILE=1' >> ~/.bashrc
echo 'export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"' >> ~/.bashrc
echo "âœ… Variables de entorno y autenticaciÃ³n configuradas"

# 3. INSTALAR DEPENDENCIAS CRÃTICAS PRIMERO
echo "ðŸ”§ 3. INSTALANDO DEPENDENCIAS CRÃTICAS..."
pip install --no-cache-dir \
    "transformers>=4.52.1" \
    "accelerate>=0.20.0" \
    fastapi \
    uvicorn \
    python-multipart \
    aiofiles \
    --upgrade

echo "âœ… Dependencias crÃ­ticas instaladas"

# 3.5. INSTALAR DEPENDENCIAS DE AUDIO (CRÃTICO)
echo "ðŸ”Š 3.5. INSTALANDO DEPENDENCIAS DE AUDIO..."
echo "ðŸ“¦ Instalando librerÃ­as de sistema para audio..."

# Instalar librerÃ­as de sistema necesarias para torchaudio backends
apt-get update && apt-get install -y \
    libsndfile1 \
    libsndfile1-dev \
    ffmpeg \
    --no-install-recommends

echo "ðŸ“¦ Instalando soundfile y librosa para manejo robusto de archivos de audio..."
pip install --no-cache-dir soundfile librosa

# Verificar que los backends de audio estÃ©n disponibles
echo "ðŸ” Verificando backends de audio..."
python -c "
import torchaudio
backends = torchaudio.list_audio_backends()
print(f'âœ… TorchAudio backends disponibles: {backends}')

try:
    import soundfile as sf
    print('âœ… SoundFile disponible')
except ImportError:
    print('âŒ SoundFile no disponible')
    exit(1)

try:
    import librosa
    print('âœ… Librosa disponible')
except ImportError:
    print('âŒ Librosa no disponible')
    exit(1)

if not backends:
    print('âŒ No hay backends de audio disponibles para torchaudio')
    print('âš ï¸  Esto podrÃ­a causar errores al guardar archivos de audio')
    exit(1)
else:
    print('âœ… Backends de audio configurados correctamente')
"

if [ $? -ne 0 ]; then
    echo "âŒ Error configurando dependencias de audio"
    exit 1
fi

echo "âœ… Dependencias de audio instaladas y verificadas"

# 4. Verificar / descargar modelo CSM-1B (MÃ‰TODO ROBUSTO CON HUGGINGFACE_HUB)
echo "ðŸ” 4. Verificando modelo CSM-1B..."
MODEL_DIR="./models/sesame-csm-1b"

# Verificar si ya existe el modelo completo
if [ -f "$MODEL_DIR/config.json" ] && ls "$MODEL_DIR"/transformers-*-of-*.safetensors 1>/dev/null 2>&1; then
    model_size=$(du -sh "$MODEL_DIR" | cut -f1)
    echo "âœ… Modelo CSM-1B encontrado: $model_size"
    echo "ðŸ“‹ Archivos safetensors encontrados:"
    ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors
else
    echo "ðŸ”„ Descargando modelo CSM-1B con huggingface_hub (mÃ©todo robusto)..."
    
    # Asegurar que huggingface_hub estÃ© actualizado
    pip install --no-cache-dir huggingface_hub --upgrade
    
    # Crear directorio models si no existe
    mkdir -p models
    
    # Descargar usando huggingface_hub (mÃ¡s robusto que git-lfs)
    python - <<'PY'
import os
from huggingface_hub import snapshot_download

print("ðŸ“¥ Iniciando descarga del modelo CSM-1B...")
print("ðŸ”— Repo: sesame/csm-1b")
print("ðŸ“ Destino: models/sesame-csm-1b")

try:
    snapshot_download(
        repo_id="sesame/csm-1b",
        local_dir="models/sesame-csm-1b",
        local_dir_use_symlinks=False,  # copia real, sin symlinks â†’ evita problemas en contenedores
        token=os.environ.get("HF_TOKEN"),
        resume_download=True  # continÃºa descarga si se interrumpiÃ³
    )
    print("âœ… Descarga completada exitosamente")
except Exception as e:
    print(f"âŒ Error durante la descarga: {e}")
    exit(1)
PY

    if [ $? -ne 0 ]; then
        echo "âŒ Error descargando modelo con huggingface_hub"
        exit 1
    fi
fi

# VerificaciÃ³n exhaustiva de archivos crÃ­ticos
echo "ðŸ” Verificando integridad del modelo..."

# Verificar archivos safetensors especÃ­ficos
if ! ls "$MODEL_DIR"/transformers-*-of-*.safetensors 1>/dev/null 2>&1; then
    echo "âŒ No se han descargado los archivos safetensors"
    echo "ðŸ“‹ Archivos esperados:"
    echo "   - transformers-00001-of-00002.safetensors"
    echo "   - transformers-00002-of-00002.safetensors"
    echo "ðŸ“ Contenido actual del directorio:"
    ls -la "$MODEL_DIR"/ || echo "Directorio no existe"
    exit 1
fi

# Verificar archivos especÃ­ficos mencionados en el error
required_files=(
    "$MODEL_DIR/transformers-00001-of-00002.safetensors"
    "$MODEL_DIR/transformers-00002-of-00002.safetensors"
    "$MODEL_DIR/config.json"
    "$MODEL_DIR/tokenizer.json"
)

missing_files=()
for file in "${required_files[@]}"; do
    if [ ! -f "$file" ]; then
        missing_files+=("$file")
    fi
done

if [ ${#missing_files[@]} -gt 0 ]; then
    echo "âŒ Archivos faltantes:"
    for file in "${missing_files[@]}"; do
        echo "   - $file"
    done
    exit 1
fi

echo "âœ… Todos los archivos crÃ­ticos del modelo estÃ¡n presentes:"
echo "ðŸ“‹ Archivos safetensors verificados:"
ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors

# Mostrar tamaÃ±o total del modelo
model_size=$(du -sh "$MODEL_DIR" | cut -f1)
echo "ðŸ“¦ TamaÃ±o total del modelo: $model_size"

# 5. Verificar dataset Elise (opcional)
echo "ðŸ” 5. Verificando dataset Elise..."
if [ -d "./datasets/csm-1b-elise" ]; then
    echo "âœ… Dataset Elise CSM ya existe"
else
    echo "âš ï¸ Dataset Elise no encontrado (opcional)"
fi

# 6. VERIFICAR DEPENDENCIAS PYTHON
echo "ðŸ”§ 6. VERIFICANDO DEPENDENCIAS PYTHON..."

# Verificar Python packages crÃ­ticos
echo "ðŸ“¦ Verificando dependencias crÃ­ticas..."
python -c "
import sys
missing = []

try:
    import torch
    print(f'âœ… PyTorch: {torch.__version__}')
except ImportError:
    missing.append('torch>=2.0.0')

try:
    import transformers
    print(f'âœ… Transformers: {transformers.__version__}')
    # Verificar que sea una versiÃ³n que soporte CSM
    if hasattr(transformers, 'CsmForConditionalGeneration'):
        print('âœ… CSM support available')
    else:
        print('âŒ CSM support not available, need Transformers >= 4.52.1')
        missing.append('transformers>=4.52.1')
except ImportError:
    missing.append('transformers>=4.52.1')

try:
    import fastapi
    print(f'âœ… FastAPI: {fastapi.__version__}')
except ImportError:
    missing.append('fastapi')

try:
    import uvicorn
    print(f'âœ… Uvicorn available')
except ImportError:
    missing.append('uvicorn')

try:
    import torchaudio
    print(f'âœ… TorchAudio: {torchaudio.__version__}')
    
    # Verificar backends de audio
    backends = torchaudio.list_audio_backends()
    print(f'âœ… TorchAudio backends: {backends}')
    if not backends:
        print('âš ï¸  Sin backends de audio - puede causar problemas')
except ImportError:
    missing.append('torchaudio')

try:
    import soundfile as sf
    print(f'âœ… SoundFile: disponible')
except ImportError:
    missing.append('soundfile')

try:
    import librosa
    print(f'âœ… Librosa: disponible')
except ImportError:
    missing.append('librosa')

if missing:
    print(f'âŒ Missing packages: {missing}')
    sys.exit(1)
else:
    print('âœ… All critical dependencies available')
"

if [ $? -ne 0 ]; then
    echo "ðŸ”§ Instalando dependencias faltantes..."
    
    # Instalar Transformers actualizado
    pip install transformers>=4.52.1 --upgrade
    
    # Instalar dependencias de API y audio
    pip install fastapi uvicorn python-multipart aiofiles soundfile librosa
    
    # Verificar instalaciÃ³n
    python -c "
from transformers import CsmForConditionalGeneration, AutoProcessor
print('âœ… CSM imports working correctly')
"
fi

# 7. Configurar estructura de directorios
echo "ðŸ“ 7. Configurando estructura de directorios..."
mkdir -p outputs temp logs voices
echo "âœ… Directorios creados"

# 8. Verificar archivo de voz de referencia
echo "ðŸ” 8. Verificando archivos de voz de referencia..."
reference_voice_old="voices/fran-fem/Ah, Â¿en serio? Vaya, eso debe ser un poco incÃ³modo para tu equipo. Y Â¿cÃ³mo lo tomaron?.wav"
reference_voice_new="voices/fran-fem/fran_fem_sample.wav"

if [ -f "$reference_voice_new" ]; then
    echo "âœ… Archivo de referencia encontrado: $reference_voice_new"
elif [ -f "$reference_voice_old" ]; then
    echo "âš ï¸ Archivo con nombre problemÃ¡tico encontrado, renombrando..."
    cd voices/fran-fem && mv *.wav fran_fem_sample.wav && cd ../..
    echo "âœ… Archivo renombrado a: $reference_voice_new"
    
    # Actualizar profiles.json si existe
    if [ -f "voices/fran-fem/profiles.json" ]; then
        echo "ðŸ”§ Actualizando profiles.json..."
        python -c "
import json
from datetime import datetime

try:
    with open('voices/fran-fem/profiles.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Actualizar path del audio
    if 'profiles' in data and len(data['profiles']) > 0:
        data['profiles'][0]['name'] = 'fran_fem_sample'
        data['profiles'][0]['audio_path'] = '/workspace/tts-v0/voices/fran-fem/fran_fem_sample.wav'
        data['updated_at'] = datetime.now().isoformat()
        
        with open('voices/fran-fem/profiles.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print('âœ… profiles.json actualizado')
    else:
        print('âš ï¸ profiles.json no tiene el formato esperado')
except Exception as e:
    print(f'âŒ Error actualizando profiles.json: {e}')
"
    fi
else
    echo "âš ï¸ Archivo de referencia no encontrado"
    echo "ðŸ’¡ El sistema funcionarÃ¡, pero sin perfil de voz predefinido"
fi

# 9. Test robusto del sistema CSM
echo "ðŸ”§ 9. Probando sistema CSM..."
python -c "
import torch
from transformers import CsmForConditionalGeneration, AutoProcessor
import os

print('ðŸ” Testing CSM system...')
try:
    model_path = './models/sesame-csm-1b'
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Verificar que los archivos especÃ­ficos existen
    safetensor_files = [
        'transformers-00001-of-00002.safetensors',
        'transformers-00002-of-00002.safetensors'
    ]
    
    print('ðŸ” Verificando archivos safetensors especÃ­ficos...')
    for file in safetensor_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024*1024)
            print(f'âœ… {file}: {size_mb:.1f} MB')
        else:
            print(f'âŒ {file}: NO ENCONTRADO')
            raise FileNotFoundError(f'Archivo crÃ­tico faltante: {file}')
    
    print(f'ðŸ“¥ Loading processor from {model_path}...')
    processor = AutoProcessor.from_pretrained(model_path)
    
    print(f'ðŸ“¥ Loading model on {device}...')
    model = CsmForConditionalGeneration.from_pretrained(
        model_path,
        device_map=device,
        torch_dtype=torch.float16 if device == 'cuda' else torch.float32
    )
    
    print('âœ… CSM system test successful!')
    
    if torch.cuda.is_available():
        gpu_info = torch.cuda.get_device_properties(0)
        memory_gb = gpu_info.total_memory / 1024**3
        print(f'ðŸ–¥ï¸ GPU: {gpu_info.name} ({memory_gb:.1f} GB)')
    
    # Test torch.compiler compatibility
    if not hasattr(torch.compiler, 'is_compiling'):
        print('âš ï¸  torch.compiler compatibility patch needed')
    else:
        print('âœ… torch.compiler compatible')
    
except Exception as e:
    print(f'âŒ CSM system test failed: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "âŒ Sistema CSM no funcionÃ³ correctamente"
    echo "ðŸ” InformaciÃ³n de debugging:"
    echo "ðŸ“ Contenido del directorio del modelo:"
    ls -la "$MODEL_DIR/" || echo "Directorio no accesible"
    exit 1
fi

# 10. InformaciÃ³n del sistema configurado
echo "ðŸ“Š 10. InformaciÃ³n del sistema configurado..."
echo "============================================================"
echo "ðŸŽ¤ CSM VOICE CLONING SYSTEM - READY"
echo "============================================================"
echo "ðŸ“¦ Sistema: CSM-1B nativo de Transformers"
echo "ðŸ¤– Modelo: models/sesame-csm-1b ($(du -sh models/sesame-csm-1b | cut -f1))"
echo "ðŸŽ­ Voces: $(ls voices/ 2>/dev/null | wc -l) perfiles disponibles"
echo "ðŸ”§ API: FastAPI + Uvicorn (voice_api_complete.py)"
echo "ðŸš€ Puerto: 7860"
echo "âœ… Archivos safetensors verificados:"
ls -la "$MODEL_DIR"/transformers-*-of-*.safetensors
echo "============================================================"

# 11. Iniciar API
echo "ðŸš€ 11. Iniciando CSM Voice Cloning API..."

# Ejecutar API completa
python voice_api_complete.py
