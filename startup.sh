#!/bin/bash
# üöÄ RUNPOD CSM VOICE CLONING STARTUP - VERSI√ìN ROBUSTA
# Configurado para: runpod/pytorch:2.1.1-py3.10-cuda12.1.1-devel-ubuntu22.04
# Sistema: CSM-1B nativo de Transformers 4.52.4+
# Incluye: Dependencias de audio (libsndfile, ffmpeg, soundfile, librosa) para backends robustos

set -e  # Exit on any error

echo "üéØ RUNPOD CSM VOICE CLONING - STARTUP ROBUSTO"
echo "============================================================"

# 1. Environment Verification
echo "üîç 1. Verificando entorno del sistema..."
cd /workspace/tts-v0

# Check GPU
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1
echo "‚úÖ GPU verification complete"

# 2. Setup environment variables
echo "üîë 2. Configurando variables de entorno..."
# Manejar RunPod Secrets y variables de entorno
if [ -n "$RUNPOD_SECRET_HF_TOKEN" ]; then
    export HF_TOKEN="$RUNPOD_SECRET_HF_TOKEN"
    echo "‚úÖ HF_TOKEN configurado desde RunPod Secret"
elif [ -n "$HF_TOKEN" ]; then
    echo "‚úÖ HF_TOKEN configurado desde variable de entorno"
else
    echo "‚ùå ERROR: HF_TOKEN no configurado"
    echo "üí° Configurar en RunPod usando Secrets: RUNPOD_SECRET_HF_TOKEN"
    echo "üí° O como variable de entorno: HF_TOKEN"
    exit 1
fi

# Configurar autenticaci√≥n de Hugging Face
echo "üîê Configurando autenticaci√≥n de Hugging Face..."
mkdir -p ~/.cache/huggingface
echo "$HF_TOKEN" > ~/.cache/huggingface/token

# Configurar git credentials para Hugging Face
git config --global credential.helper store
echo "https://MrMoferFRAN:$HF_TOKEN@huggingface.co" > ~/.git-credentials

# Tambi√©n configurar usando huggingface-hub
pip install --no-cache-dir huggingface-hub --upgrade
python -c "from huggingface_hub import login; login('$HF_TOKEN')" 2>/dev/null || echo "‚ö†Ô∏è huggingface-hub login failed, using git credentials"

export NO_TORCH_COMPILE=1
export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"
echo 'export NO_TORCH_COMPILE=1' >> ~/.bashrc
echo 'export PYTHONPATH="/workspace/tts-v0:$PYTHONPATH"' >> ~/.bashrc
echo "‚úÖ Variables de entorno y autenticaci√≥n configuradas"

# 3. INSTALAR DEPENDENCIAS CR√çTICAS PRIMERO
echo "üîß 3. INSTALANDO DEPENDENCIAS CR√çTICAS..."
pip install --no-cache-dir \
    "transformers>=4.52.1" \
    "accelerate>=0.20.0" \
    fastapi \
    uvicorn \
    python-multipart \
    aiofiles \
    --upgrade

echo "‚úÖ Dependencias cr√≠ticas instaladas"

# 3.5. INSTALAR DEPENDENCIAS DE AUDIO (CR√çTICO)
echo "üîä 3.5. INSTALANDO DEPENDENCIAS DE AUDIO..."
echo "üì¶ Instalando librer√≠as de sistema para audio..."

# Instalar librer√≠as de sistema necesarias para torchaudio backends
apt-get update && apt-get install -y \
    libsndfile1 \
    libsndfile1-dev \
    ffmpeg \
    --no-install-recommends

echo "üì¶ Instalando soundfile y librosa para manejo robusto de archivos de audio..."
pip install --no-cache-dir soundfile librosa

# Verificar que los backends de audio est√©n disponibles
echo "üîç Verificando backends de audio..."
python -c "
import torchaudio
backends = torchaudio.list_audio_backends()
print(f'‚úÖ TorchAudio backends disponibles: {backends}')

try:
    import soundfile as sf
    print('‚úÖ SoundFile disponible')
except ImportError:
    print('‚ùå SoundFile no disponible')
    exit(1)

try:
    import librosa
    print('‚úÖ Librosa disponible')
except ImportError:
    print('‚ùå Librosa no disponible')
    exit(1)

if not backends:
    print('‚ùå No hay backends de audio disponibles para torchaudio')
    print('‚ö†Ô∏è  Esto podr√≠a causar errores al guardar archivos de audio')
    exit(1)
else:
    print('‚úÖ Backends de audio configurados correctamente')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Error configurando dependencias de audio"
    exit 1
fi

echo "‚úÖ Dependencias de audio instaladas y verificadas"

# 4. Descargar modelo CSM-1B Turbo INT8
echo "üîç 4. Descargando modelo CSM-1B Turbo INT8..."
TURBO_DIR="./models/csm-1b-turbo"

# Verificar si ya existe el modelo turbo completo
if [ -f "$TURBO_DIR/model.safetensors" ] && [ -f "$TURBO_DIR/transformers-00001-of-00002.safetensors" ] && [ -f "$TURBO_DIR/transformers-00002-of-00002.safetensors" ]; then
    model_size=$(du -sh "$TURBO_DIR/model.safetensors" | cut -f1)
    echo "‚úÖ Modelo CSM-1B Turbo completo encontrado: $model_size"
else
    echo "üîÑ Descargando modelo CSM-1B Turbo desde lunahr/csm-1b-safetensors-quants..."
    
    # Crear directorio models si no existe
    mkdir -p "$TURBO_DIR"
    
    # 4.1. Descargar modelo uint8 cuantizado
    echo "üì• 4.1. Descargando modelo uint8 cuantizado..."
    python - <<'PY'
import os
from huggingface_hub import hf_hub_download

print("üì• Descargando model_uint8.safetensors...")
print("üîó Repo: lunahr/csm-1b-safetensors-quants")
print("üìÅ Destino: models/csm-1b-turbo")

try:
    downloaded_file = hf_hub_download(
        repo_id="lunahr/csm-1b-safetensors-quants",
        filename="model_uint8.safetensors",
        local_dir="models/csm-1b-turbo",
        local_dir_use_symlinks=False,
        token=os.environ.get("HF_TOKEN")
    )
    print("‚úÖ Modelo turbo descargado exitosamente")
except Exception as e:
    print(f"‚ùå Error durante la descarga: {e}")
    exit(1)
PY

    if [ $? -ne 0 ]; then
        echo "‚ùå Error descargando modelo turbo"
        exit 1
    fi
    
    # 4.2. Copiar como model.safetensors
    echo "üîç 4.2. Copiando modelo como model.safetensors..."
    if [ -f "$TURBO_DIR/model_uint8.safetensors" ]; then
        cp "$TURBO_DIR/model_uint8.safetensors" "$TURBO_DIR/model.safetensors"
        echo "‚úÖ model_uint8.safetensors copiado como model.safetensors"
    else
        echo "‚ùå No se encontr√≥ model_uint8.safetensors"
        exit 1
    fi
    
    # 4.3. Descargar archivos de configuraci√≥n desde sesame/csm-1b
    echo "üì• 4.3. Descargando archivos de configuraci√≥n..."
    python - <<'PY'
import os
from huggingface_hub import hf_hub_download

print('üì• Descargando archivos de configuraci√≥n CSM...')
print('üîó Repo: sesame/csm-1b')
print('üìÅ Destino: models/csm-1b-turbo')

config_files = [
    'config.json',
    'tokenizer.json',
    'tokenizer_config.json',
    'preprocessor_config.json',
    'special_tokens_map.json',
    'generation_config.json',
    'chat_template.jinja'
]

for filename in config_files:
    try:
        print(f'üì• Descargando {filename}...')
        downloaded_file = hf_hub_download(
            repo_id='sesame/csm-1b',
            filename=filename,
            local_dir='models/csm-1b-turbo',
            token=os.environ.get('HF_TOKEN')
        )
        print(f'‚úÖ {filename} descargado')
    except Exception as e:
        print(f'‚ùå Error descargando {filename}: {e}')
        exit(1)

print('‚úÖ Archivos de configuraci√≥n descargados')
PY

    if [ $? -ne 0 ]; then
        echo "‚ùå Error descargando archivos de configuraci√≥n"
        exit 1
    fi
    
    # 4.4. Descargar √≠ndice de transformers
    echo "üì• 4.4. Descargando √≠ndice de transformers..."
    python - <<'PY'
import os
from huggingface_hub import hf_hub_download

print('üì• Descargando transformers.safetensors.index.json...')
downloaded_file = hf_hub_download(
    repo_id='sesame/csm-1b',
    filename='transformers.safetensors.index.json',
    local_dir='models/csm-1b-turbo',
    token=os.environ.get('HF_TOKEN')
)
print('‚úÖ transformers.safetensors.index.json descargado')
PY

    if [ $? -ne 0 ]; then
        echo "‚ùå Error descargando √≠ndice de transformers"
        exit 1
    fi
    
    # 4.5. Descargar archivos transformers
    echo "üì• 4.5. Descargando archivos transformers..."
    python - <<'PY'
import os
from huggingface_hub import hf_hub_download

print('üì• Descargando archivos transformers...')
print('üîó Repo: sesame/csm-1b')
print('üìÅ Destino: models/csm-1b-turbo')

transformer_files = [
    'transformers-00001-of-00002.safetensors',
    'transformers-00002-of-00002.safetensors'
]

for filename in transformer_files:
    try:
        print(f'üì• Descargando {filename}...')
        downloaded_file = hf_hub_download(
            repo_id='sesame/csm-1b',
            filename=filename,
            local_dir='models/csm-1b-turbo',
            token=os.environ.get('HF_TOKEN')
        )
        print(f'‚úÖ {filename} descargado')
    except Exception as e:
        print(f'‚ùå Error descargando {filename}: {e}')
        exit(1)

print('‚úÖ Archivos transformers descargados')
PY

    if [ $? -ne 0 ]; then
        echo "‚ùå Error descargando archivos transformers"
        exit 1
    fi
fi

# Mostrar informaci√≥n del modelo turbo
if [ -f "$TURBO_DIR/model.safetensors" ]; then
    model_size=$(du -sh "$TURBO_DIR/model.safetensors" | cut -f1)
    echo "üì¶ Tama√±o del modelo turbo: $model_size"
fi

# Verificar que todos los archivos est√©n presentes
echo "üîç Verificando archivos del modelo turbo..."
required_files=(
    "model.safetensors"
    "config.json"
    "tokenizer.json"
    "transformers.safetensors.index.json"
    "transformers-00001-of-00002.safetensors"
    "transformers-00002-of-00002.safetensors"
)

missing_files=()
for file in "${required_files[@]}"; do
    if [ ! -f "$TURBO_DIR/$file" ]; then
        missing_files+=("$file")
    fi
done

if [ ${#missing_files[@]} -eq 0 ]; then
    echo "‚úÖ Todos los archivos del modelo turbo est√°n presentes"
else
    echo "‚ùå Archivos faltantes: ${missing_files[*]}"
    exit 1
fi


# 5. Verificar dataset Elise (opcional)
echo "üîç 5. Verificando dataset Elise..."
if [ -d "./datasets/csm-1b-elise" ]; then
    echo "‚úÖ Dataset Elise CSM ya existe"
else
    echo "‚ö†Ô∏è Dataset Elise no encontrado (opcional)"
fi

# 6. VERIFICAR DEPENDENCIAS PYTHON
echo "üîß 6. VERIFICANDO DEPENDENCIAS PYTHON..."

# Verificar Python packages cr√≠ticos
echo "üì¶ Verificando dependencias cr√≠ticas..."
python -c "
import sys
missing = []

try:
    import torch
    print(f'‚úÖ PyTorch: {torch.__version__}')
except ImportError:
    missing.append('torch>=2.0.0')

try:
    import transformers
    print(f'‚úÖ Transformers: {transformers.__version__}')
    # Verificar que sea una versi√≥n que soporte CSM
    if hasattr(transformers, 'CsmForConditionalGeneration'):
        print('‚úÖ CSM support available')
    else:
        print('‚ùå CSM support not available, need Transformers >= 4.52.1')
        missing.append('transformers>=4.52.1')
except ImportError:
    missing.append('transformers>=4.52.1')

try:
    import fastapi
    print(f'‚úÖ FastAPI: {fastapi.__version__}')
except ImportError:
    missing.append('fastapi')

try:
    import uvicorn
    print(f'‚úÖ Uvicorn available')
except ImportError:
    missing.append('uvicorn')

try:
    import torchaudio
    print(f'‚úÖ TorchAudio: {torchaudio.__version__}')
    
    # Verificar backends de audio
    backends = torchaudio.list_audio_backends()
    print(f'‚úÖ TorchAudio backends: {backends}')
    if not backends:
        print('‚ö†Ô∏è  Sin backends de audio - puede causar problemas')
except ImportError:
    missing.append('torchaudio')

try:
    import soundfile as sf
    print(f'‚úÖ SoundFile: disponible')
except ImportError:
    missing.append('soundfile')

try:
    import librosa
    print(f'‚úÖ Librosa: disponible')
except ImportError:
    missing.append('librosa')

if missing:
    print(f'‚ùå Missing packages: {missing}')
    sys.exit(1)
else:
    print('‚úÖ All critical dependencies available')
"

if [ $? -ne 0 ]; then
    echo "üîß Instalando dependencias faltantes..."
    
    # Instalar Transformers actualizado
    pip install transformers>=4.52.1 --upgrade
    
    # Instalar dependencias de API y audio
    pip install fastapi uvicorn python-multipart aiofiles soundfile librosa
    
    # Verificar instalaci√≥n
    python -c "
from transformers import CsmForConditionalGeneration, AutoProcessor
print('‚úÖ CSM imports working correctly')
"
fi

# 7. Configurar estructura de directorios
echo "üìÅ 7. Configurando estructura de directorios..."
mkdir -p outputs temp logs voices
echo "‚úÖ Directorios creados"

# 8. Verificar archivo de voz de referencia
echo "üîç 8. Verificando archivos de voz de referencia..."
reference_voice_old="voices/fran-fem/Ah, ¬øen serio? Vaya, eso debe ser un poco inc√≥modo para tu equipo. Y ¬øc√≥mo lo tomaron?.wav"
reference_voice_new="voices/fran-fem/fran_fem_sample.wav"

if [ -f "$reference_voice_new" ]; then
    echo "‚úÖ Archivo de referencia encontrado: $reference_voice_new"
elif [ -f "$reference_voice_old" ]; then
    echo "‚ö†Ô∏è Archivo con nombre problem√°tico encontrado, renombrando..."
    cd voices/fran-fem && mv *.wav fran_fem_sample.wav && cd ../..
    echo "‚úÖ Archivo renombrado a: $reference_voice_new"
    
    # Actualizar profiles.json si existe
    if [ -f "voices/fran-fem/profiles.json" ]; then
        echo "üîß Actualizando profiles.json..."
        python -c "
import json
from datetime import datetime

try:
    with open('voices/fran-fem/profiles.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Actualizar path del audio
    if 'profiles' in data and len(data['profiles']) > 0:
        data['profiles'][0]['name'] = 'fran_fem_sample'
        data['profiles'][0]['audio_path'] = '/workspace/tts-v0/voices/fran-fem/fran_fem_sample.wav'
        data['updated_at'] = datetime.now().isoformat()
        
        with open('voices/fran-fem/profiles.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print('‚úÖ profiles.json actualizado')
    else:
        print('‚ö†Ô∏è profiles.json no tiene el formato esperado')
except Exception as e:
    print(f'‚ùå Error actualizando profiles.json: {e}')
"
    fi
else
    echo "‚ö†Ô∏è Archivo de referencia no encontrado"
    echo "üí° El sistema funcionar√°, pero sin perfil de voz predefinido"
fi

# 9. Test robusto del sistema CSM Turbo
echo "üîß 9. Probando sistema CSM Turbo..."
python -c "
import torch
from transformers import CsmForConditionalGeneration, AutoProcessor
import os

print('üîç Testing CSM Turbo system...')
try:
    model_path = './models/csm-1b-turbo'
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Verificar que el archivo model.safetensors existe
    model_file = os.path.join(model_path, 'model.safetensors')
    if os.path.exists(model_file):
        size_mb = os.path.getsize(model_file) / (1024*1024)
        print(f'‚úÖ model.safetensors: {size_mb:.1f} MB')
    else:
        print(f'‚ùå model.safetensors: NO ENCONTRADO')
        raise FileNotFoundError('Archivo cr√≠tico faltante: model.safetensors')
    
    print(f'üì• Loading model from {model_path} on {device}...')
    model = CsmForConditionalGeneration.from_pretrained(
        model_path,
        device_map=device,
        torch_dtype=torch.float16 if device == 'cuda' else torch.float32
    )
    
    print('‚úÖ CSM Turbo system test successful!')
    
    if torch.cuda.is_available():
        gpu_info = torch.cuda.get_device_properties(0)
        memory_gb = gpu_info.total_memory / 1024**3
        print(f'üñ•Ô∏è GPU: {gpu_info.name} ({memory_gb:.1f} GB)')
    
    # Test torch.compiler compatibility
    if not hasattr(torch.compiler, 'is_compiling'):
        print('‚ö†Ô∏è  torch.compiler compatibility patch needed')
    else:
        print('‚úÖ torch.compiler compatible')
    
except Exception as e:
    print(f'‚ùå CSM Turbo system test failed: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå Sistema CSM Turbo no funcion√≥ correctamente"
    echo "üîç Informaci√≥n de debugging:"
    echo "üìÅ Contenido del directorio del modelo:"
    ls -la "$TURBO_DIR/" || echo "Directorio no accesible"
    exit 1
fi

# 10. Informaci√≥n del sistema configurado
echo "üìä 10. Informaci√≥n del sistema configurado..."
echo "============================================================"
echo "üé§ CSM VOICE CLONING SYSTEM - READY"
echo "============================================================"
echo "üì¶ Sistema: CSM-1B Turbo INT8"
echo "ü§ñ Modelo: models/csm-1b-turbo ($(du -sh models/csm-1b-turbo/model.safetensors | cut -f1))"
echo "üé≠ Voces: $(ls voices/ 2>/dev/null | wc -l) perfiles disponibles"
echo "üîß API: FastAPI + Uvicorn (voice_api_complete.py)"
echo "üöÄ Puerto: 7860"
echo "‚úÖ Modelo turbo verificado:"
ls -la "$TURBO_DIR"/model.safetensors
echo "============================================================"

# 11. Verificar compatibilidad GPU (RTX 5090)
echo "üîç 11. Verificando compatibilidad GPU..."
python -c "
import torch
import sys

if torch.cuda.is_available():
    try:
        device_props = torch.cuda.get_device_properties(0)
        gpu_name = device_props.name
        compute_capability = f'{device_props.major}.{device_props.minor}'
        
        print(f'üñ•Ô∏è GPU: {gpu_name}')
        print(f'üîß Compute Capability: {compute_capability}')
        
        # Check for RTX 5090 compatibility issue
        if 'RTX 5090' in gpu_name or device_props.major >= 12:
            print('üö® RTX 5090 detectada!')
            pytorch_version = torch.__version__
            major_version = int(pytorch_version.split(\".\")[0])
            minor_version = int(pytorch_version.split(\".\")[1])
            
            if major_version < 2 or (major_version == 2 and minor_version < 5):
                print('‚ùå PyTorch incompatible con RTX 5090')
                print('‚ö†Ô∏è RTX 5090 requires PyTorch 2.5+ with CUDA 12.4+')
                print('üîß Soluciones disponibles:')
                print('   1. Actualizar: pip install torch==2.5.0 --index-url https://download.pytorch.org/whl/cu124')
                print('   2. Modo CPU: export CUDA_VISIBLE_DEVICES=\"\"')
                sys.exit(1)
            else:
                print('‚úÖ PyTorch compatible con RTX 5090')
        else:
            print('‚úÖ GPU compatible')
    except Exception as e:
        print(f'‚ö†Ô∏è Error verificando GPU: {e}')
        print('üîÑ Continuando con detecci√≥n autom√°tica')
else:
    print('üíª Modo CPU detectado')
"

gpu_check_result=$?

# 12. Iniciar API
if [ $gpu_check_result -eq 0 ]; then
    echo "üöÄ 12. Iniciando CSM Voice Cloning API..."
    
    # Ejecutar API completa
    python voice_api_complete.py
else
    echo "‚ö†Ô∏è GPU incompatible detectada (RTX 5090 con PyTorch antiguo)"
    echo "üîß ¬øContinuar en modo CPU? (y/N): "
    read -r response
    
    if [[ "$response" =~ ^[Yy]$ ]]; then
        echo "üîÑ Iniciando en modo CPU..."
        export CUDA_VISIBLE_DEVICES=''
        python voice_api_complete.py
    else
        echo "‚ùå Proceso detenido. Actualiza PyTorch para RTX 5090:"
        echo "   pip install torch==2.5.0 torchvision==0.20.0 --index-url https://download.pytorch.org/whl/cu124"
                 exit 1
     fi
fi
