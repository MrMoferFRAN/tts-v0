#!/usr/bin/env python3
"""
Investigate CSM processor.save_audio format requirements
"""
import os
import torch
import torchaudio
from pathlib import Path
from transformers import AutoTokenizer, AutoProcessor, CsmForConditionalGeneration

os.environ["NO_TORCH_COMPILE"] = "1"

def investigate_save_audio_format():
    """Investigate what format save_audio expects"""
    print("ğŸ” INVESTIGANDO FORMATO DE save_audio")
    print("=" * 60)
    
    base_model_path = "/workspace/runPodtts/models/sesame-csm-1b"
    
    try:
        print("ğŸ“¥ Cargando modelo...")
        processor = AutoProcessor.from_pretrained(base_model_path)
        model = CsmForConditionalGeneration.from_pretrained(
            base_model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True
        )
        
        print(f"âœ… Modelo cargado")
        
        # Check processor methods
        print("\nğŸ” MÃ‰TODOS DEL PROCESSOR:")
        for attr in dir(processor):
            if 'audio' in attr.lower() or 'save' in attr.lower():
                print(f"   ğŸ”¸ {attr}")
        
        # Check save_audio method signature
        if hasattr(processor, 'save_audio'):
            print(f"\nğŸ“‹ save_audio method: {processor.save_audio}")
            print(f"ğŸ“‹ save_audio __doc__: {processor.save_audio.__doc__}")
        
        # Generate some tokens first
        conversation = [
            {"role": "0", "content": [{"type": "text", "text": "Hello!"}]}
        ]
        
        inputs = processor.apply_chat_template(
            conversation, tokenize=True, return_dict=True, return_tensors="pt"
        )
        inputs = {k: v.to("cuda") if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
        
        print(f"\nğŸµ Generando tokens para anÃ¡lisis...")
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=50)
        
        print(f"ğŸ“Š Outputs shape: {outputs.shape}")
        
        # Analyze what save_audio expects
        input_length = inputs['input_ids'].shape[1]
        audio_tokens = outputs[:, input_length:]
        
        print(f"ğŸ“Š Audio tokens shape: {audio_tokens.shape}")
        print(f"ğŸ“Š Audio tokens dtype: {audio_tokens.dtype}")
        print(f"ğŸ“Š Audio tokens device: {audio_tokens.device}")
        print(f"ğŸ“Š Audio tokens min/max: {audio_tokens.min()}/{audio_tokens.max()}")
        
        # Try different formats
        print(f"\nğŸ§ª PROBANDO DIFERENTES FORMATOS:")
        
        # Format 1: Original 3D tensor
        print(f"1ï¸âƒ£ Formato original [1, seq, features]: {audio_tokens.shape}")
        try:
            test_path_1 = "/workspace/runPodtts/outputs/test_format_1.wav"
            processor.save_audio(audio_tokens, test_path_1)
            print(f"   âœ… Ã‰xito: {test_path_1}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Format 2: Remove batch dimension
        print(f"2ï¸âƒ£ Sin batch dimension [seq, features]: {audio_tokens.squeeze(0).shape}")
        try:
            test_path_2 = "/workspace/runPodtts/outputs/test_format_2.wav"
            processor.save_audio(audio_tokens.squeeze(0), test_path_2)
            print(f"   âœ… Ã‰xito: {test_path_2}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Format 3: Flatten completely
        print(f"3ï¸âƒ£ Completamente flat [total_samples]: {audio_tokens.flatten().shape}")
        try:
            test_path_3 = "/workspace/runPodtts/outputs/test_format_3.wav"
            processor.save_audio(audio_tokens.flatten(), test_path_3)
            print(f"   âœ… Ã‰xito: {test_path_3}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Format 4: Try full output tensor
        print(f"4ï¸âƒ£ Tensor completo [1, total_seq, features]: {outputs.shape}")
        try:
            test_path_4 = "/workspace/runPodtts/outputs/test_format_4.wav"
            processor.save_audio(outputs, test_path_4)
            print(f"   âœ… Ã‰xito: {test_path_4}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Format 5: Convert to numpy
        print(f"5ï¸âƒ£ Como numpy array: {audio_tokens.cpu().numpy().shape}")
        try:
            test_path_5 = "/workspace/runPodtts/outputs/test_format_5.wav"
            processor.save_audio(audio_tokens.cpu().numpy(), test_path_5)
            print(f"   âœ… Ã‰xito: {test_path_5}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Format 6: Try different reshaping
        reshaped = audio_tokens.reshape(-1, audio_tokens.shape[-1])
        print(f"6ï¸âƒ£ Reshape [total_seq, features]: {reshaped.shape}")
        try:
            test_path_6 = "/workspace/runPodtts/outputs/test_format_6.wav"
            processor.save_audio(reshaped, test_path_6)
            print(f"   âœ… Ã‰xito: {test_path_6}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
        
        # Check which files were created successfully
        print(f"\nğŸ“ ARCHIVOS CREADOS EXITOSAMENTE:")
        output_dir = Path("/workspace/runPodtts/outputs")
        for i in range(1, 7):
            test_path = output_dir / f"test_format_{i}.wav"
            if test_path.exists():
                size = test_path.stat().st_size
                try:
                    audio, sr = torchaudio.load(test_path)
                    duration = audio.shape[1] / sr
                    print(f"   âœ… Format {i}: {test_path} ({size} bytes, {duration:.2f}s)")
                except Exception as load_error:
                    print(f"   âš ï¸  Format {i}: {test_path} ({size} bytes, error loading: {load_error})")
            else:
                print(f"   âŒ Format {i}: No creado")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error general: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ” INVESTIGACIÃ“N DE FORMATO save_audio")
    print("=" * 50)
    
    success = investigate_save_audio_format()
    
    if success:
        print("\nğŸ‰ INVESTIGACIÃ“N COMPLETADA")
        print("ğŸ” Revisa los archivos test_format_*.wav")
        print("ğŸ“Š Los que funcionaron nos dicen el formato correcto")
    else:
        print("\nâŒ INVESTIGACIÃ“N FALLÃ“")
    
    torch.cuda.empty_cache()

if __name__ == "__main__":
    main() 