# ğŸ¤ Voice Cloning API Complete - CSM-1B Turbo

API completa de clonaciÃ³n de voz con gestiÃ³n avanzada de perfiles y **modo turbo** para inferencia ultrarrÃ¡pida.

## ğŸš€ Nuevas CaracterÃ­sticas - Modo Turbo

### âœ¨ CaracterÃ­sticas Principales

- **ğŸ¯ Dual Model Support**: Modelo normal (float32) y turbo (int8 cuantizado)
- **âš¡ Modo Turbo**: Inferencia ultrarrÃ¡pida con modelo cuantizado int8
- **ğŸ“ GestiÃ³n por Carpetas**: Cada voz tiene su propia carpeta con mÃºltiples muestras
- **ğŸ“¤ Upload Inteligente**: ValidaciÃ³n automÃ¡tica 3-9s, WAV 24kHz mono normalizado
- **ğŸ¯ ClonaciÃ³n Precisa**: SelecciÃ³n especÃ­fica de muestras para mejor calidad
- **ğŸ“Š AnÃ¡lisis Completo**: EstadÃ­sticas detalladas y mÃ©tricas de calidad

### ğŸ—ï¸ Estructura de Modelos

```
models/
â”œâ”€â”€ sesame-csm-1b/           # Modelo normal (float32)
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â””â”€â”€ csm-1b-turbo/            # Modelo turbo (int8 cuantizado)
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model_int8.safetensors  # â† Modelo cuantizado principal
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ ...
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Descargar Modelo Turbo

```bash
# El modelo normal ya estÃ¡ disponible
# Descargar modelo turbo cuantizado
mkdir -p models/csm-1b-turbo
cd models/csm-1b-turbo
wget https://huggingface.co/lunahr/csm-1b-safetensors-quants/resolve/main/model_int8.safetensors

# Copiar archivos de configuraciÃ³n del modelo normal
cp -r ../sesame-csm-1b/* ./
```

### 2. Iniciar API

```bash
python voice_api_complete.py
```

La API cargarÃ¡ automÃ¡ticamente ambos modelos al iniciar:
- âœ… Modelo normal: Mayor calidad, mÃ¡s lento
- ğŸš€ Modelo turbo: Velocidad ultrarrÃ¡pida, calidad comparable

## ğŸ“‹ API Endpoints

### ğŸ” Health Check Mejorado

```bash
GET /health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "normal_model": {
    "loaded": true,
    "processor_loaded": true,
    "path": "./models/sesame-csm-1b"
  },
  "turbo_model": {
    "loaded": true,
    "processor_loaded": true,
    "path": "./models/csm-1b-turbo",
    "available": true
  },
  "gpu_available": true,
  "gpu_info": {...},
  "voice_collections": 2,
  "total_voice_samples": 5
}
```

### ğŸ¤ ClonaciÃ³n de Voz con Modo Turbo

```bash
POST /clone
```

**ParÃ¡metros:**
- `text` (requerido): Texto a sintetizar
- `voice_id` (opcional): ID de la colecciÃ³n de voz
- `sample_name` (opcional): Nombre especÃ­fico de muestra
- `temperature` (opcional): Temperatura de sampling (default: 0.8)
- `max_tokens` (opcional): MÃ¡ximo tokens a generar (default: 512)
- **`turbo` (nuevo)**: Usar modo turbo (default: false)
- `output_format` (opcional): Formato de salida (default: wav)

## ğŸ§ª Ejemplos de Uso

### 1. Modo Normal (Mayor Calidad)

```bash
curl -X POST 'http://localhost:7860/clone' \
  -F 'text=Hola, soy una voz clonada con alta calidad' \
  -F 'voice_id=fran-fem' \
  -F 'turbo=false'
```

### 2. Modo Turbo (UltrarrÃ¡pido)

```bash
curl -X POST 'http://localhost:7860/clone' \
  -F 'text=Hola, soy una voz clonada ultra rÃ¡pida' \
  -F 'voice_id=fran-fem' \
  -F 'turbo=true'
```

### 3. ComparaciÃ³n de Velocidad

```python
import requests
import time

# Modo normal
start = time.time()
response_normal = requests.post('http://localhost:7860/clone', data={
    'text': 'Texto de prueba',
    'voice_id': 'mi-voz',
    'turbo': 'false'
})
time_normal = time.time() - start

# Modo turbo
start = time.time()
response_turbo = requests.post('http://localhost:7860/clone', data={
    'text': 'Texto de prueba',
    'voice_id': 'mi-voz',
    'turbo': 'true'
})
time_turbo = time.time() - start

speedup = time_normal / time_turbo
print(f"Speedup: {speedup:.2f}x mÃ¡s rÃ¡pido")
```

## ğŸ§ª Script de Prueba

Incluimos un script de prueba que compara automÃ¡ticamente ambos modelos:

```bash
python test_turbo.py
```

**Funciones del script:**
- âœ… Verifica estado de ambos modelos
- ğŸµ Genera audio con ambos modelos
- â±ï¸ Mide y compara velocidades
- ğŸ“Š Calcula speedup automÃ¡ticamente
- ğŸ’¾ Guarda archivos de prueba

## ğŸ“Š Benchmarks Esperados

| Modo | Velocidad | Calidad | Uso RAM | Uso VRAM |
|------|-----------|---------|---------|----------|
| Normal | 1.0x | Alta | ~8GB | ~6GB |
| Turbo | **2-3x** | Comparable | ~6GB | ~4GB |

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

```bash
export NO_TORCH_COMPILE=1           # Desactivar compilaciÃ³n torch
export HF_TOKEN=your_token_here     # Token Hugging Face
export CUDA_VISIBLE_DEVICES=0       # GPU especÃ­fica
```

### ParÃ¡metros de Modelo

```python
# En voice_api_complete.py
manager = CSMVoiceManager(
    model_path="./models/sesame-csm-1b",     # Modelo normal
    turbo_model_path="./models/csm-1b-turbo", # Modelo turbo
    voices_dir="./voices"                     # Directorio de voces
)
```

## ğŸš€ Optimizaciones Implementadas

### Modelo Turbo (int8)
- **CuantizaciÃ³n int8**: Reduce tamaÃ±o del modelo ~50%
- **Memoria optimizada**: Menor uso de VRAM
- **Compatibilidad**: Misma API, misma calidad
- **Speed boost**: 2-3x mÃ¡s rÃ¡pido

### Carga Dual
- **Precarga**: Ambos modelos se cargan al inicio
- **SelecciÃ³n dinÃ¡mica**: Cambio instantÃ¡neo entre modelos
- **Fallback**: Si turbo falla, usa modelo normal automÃ¡ticamente

## ğŸ¯ Casos de Uso Recomendados

### Modo Normal
- âœ… ProducciÃ³n de alta calidad
- âœ… Voces para contenido final
- âœ… Cuando la calidad es prioritaria

### Modo Turbo
- âœ… Prototipado rÃ¡pido
- âœ… Aplicaciones en tiempo real
- âœ… Pruebas y desarrollo
- âœ… APIs con alta concurrencia

## ğŸ” Troubleshooting

### Error: Turbo model not available
```bash
# Verificar que el modelo turbo estÃ© descargado
ls -la models/csm-1b-turbo/model_int8.safetensors

# Si no existe, descargar:
cd models/csm-1b-turbo
wget https://huggingface.co/lunahr/csm-1b-safetensors-quants/resolve/main/model_int8.safetensors
```

### Memoria insuficiente
```python
# Usar modo turbo para reducir uso de memoria
response = requests.post('/clone', data={
    'text': 'Mi texto',
    'turbo': 'true'  # Menor uso de VRAM
})
```

## ğŸ“ˆ Roadmap

- [ ] **Modelos adicionales**: Soporte para mÃ¡s variantes cuantizadas
- [ ] **Auto-selection**: SelecciÃ³n automÃ¡tica segÃºn carga del sistema
- [ ] **Streaming**: GeneraciÃ³n de audio en tiempo real
- [ ] **Batch processing**: Procesamiento de mÃºltiples textos
- [ ] **Model caching**: Cache inteligente para cambio de modelos

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature
3. Prueba con ambos modelos (normal y turbo)
4. EnvÃ­a un pull request

## ğŸ“„ Licencia

Este proyecto utiliza el modelo CSM-1B bajo su licencia correspondiente.

---

**ğŸš€ Â¡Disfruta de la velocidad ultrarrÃ¡pida del modo turbo!** 